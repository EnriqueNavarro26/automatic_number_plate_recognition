{"cells":[{"cell_type":"markdown","metadata":{},"source":["This Notebook is recommended to be run in Kaggle Notebook with GPU Accelerator. The dataset is available in the link below. \n","\n","https://www.kaggle.com/andrewmvd/car-plate-detection"]},{"cell_type":"markdown","metadata":{},"source":["## 01_DataProcessingAndTraining"]},{"cell_type":"markdown","metadata":{},"source":["### Import libraries"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T11:11:53.237941Z","iopub.status.busy":"2023-10-04T11:11:53.237559Z","iopub.status.idle":"2023-10-04T11:11:53.242856Z","shell.execute_reply":"2023-10-04T11:11:53.241848Z","shell.execute_reply.started":"2023-10-04T11:11:53.237912Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import xml.etree.ElementTree as xet\n","from glob import glob\n","from skimage import io, color\n","from shutil import copy"]},{"cell_type":"markdown","metadata":{},"source":["### Required Data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:01.379448Z","iopub.status.busy":"2023-10-04T10:23:01.378962Z","iopub.status.idle":"2023-10-04T10:23:07.013276Z","shell.execute_reply":"2023-10-04T10:23:07.012327Z","shell.execute_reply.started":"2023-10-04T10:23:01.379418Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepath</th>\n","      <th>xmin</th>\n","      <th>xmax</th>\n","      <th>ymin</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>209</td>\n","      <td>283</td>\n","      <td>135</td>\n","      <td>169</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>191</td>\n","      <td>242</td>\n","      <td>147</td>\n","      <td>169</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>115</td>\n","      <td>277</td>\n","      <td>115</td>\n","      <td>153</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>36</td>\n","      <td>62</td>\n","      <td>175</td>\n","      <td>186</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>71</td>\n","      <td>215</td>\n","      <td>205</td>\n","      <td>246</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            filepath  xmin  xmax  ymin  ymax\n","0  /kaggle/input/car-plate-detection/annotations/...   209   283   135   169\n","1  /kaggle/input/car-plate-detection/annotations/...   191   242   147   169\n","2  /kaggle/input/car-plate-detection/annotations/...   115   277   115   153\n","3  /kaggle/input/car-plate-detection/annotations/...    36    62   175   186\n","4  /kaggle/input/car-plate-detection/annotations/...    71   215   205   246"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["path = glob('/kaggle/input/car-plate-detection/annotations/*.xml')\n","labels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\n","for filename in path:\n","\n","    info = xet.parse(filename)\n","    root = info.getroot()\n","    member_object = root.find('object')\n","    labels_info = member_object.find('bndbox')\n","    xmin = int(labels_info.find('xmin').text)\n","    xmax = int(labels_info.find('xmax').text)\n","    ymin = int(labels_info.find('ymin').text)\n","    ymax = int(labels_info.find('ymax').text)\n","\n","    labels_dict['filepath'].append(filename)\n","    labels_dict['xmin'].append(xmin)\n","    labels_dict['xmax'].append(xmax)\n","    labels_dict['ymin'].append(ymin)\n","    labels_dict['ymax'].append(ymax)\n","    \n","df = pd.DataFrame(labels_dict)\n","df.to_csv('labels.csv',index=False)\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:10.087874Z","iopub.status.busy":"2023-10-04T10:23:10.087523Z","iopub.status.idle":"2023-10-04T10:23:10.094824Z","shell.execute_reply":"2023-10-04T10:23:10.093671Z","shell.execute_reply.started":"2023-10-04T10:23:10.087848Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/car-plate-detection/images/Cars339.png\n"]}],"source":["def getFilename(filename):\n","    filename_image = xet.parse(filename).getroot().find('filename').text\n","    filepath_image = os.path.join('/kaggle/input/car-plate-detection/images',filename_image)\n","    return filepath_image\n","\n","filename = df[\"filepath\"][0]\n","print(getFilename(filename))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:10.858990Z","iopub.status.busy":"2023-10-04T10:23:10.857986Z","iopub.status.idle":"2023-10-04T10:23:11.256705Z","shell.execute_reply":"2023-10-04T10:23:11.255833Z","shell.execute_reply.started":"2023-10-04T10:23:10.858954Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepath</th>\n","      <th>xmin</th>\n","      <th>xmax</th>\n","      <th>ymin</th>\n","      <th>ymax</th>\n","      <th>filename</th>\n","      <th>width</th>\n","      <th>height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>209</td>\n","      <td>283</td>\n","      <td>135</td>\n","      <td>169</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars3...</td>\n","      <td>500</td>\n","      <td>300</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>191</td>\n","      <td>242</td>\n","      <td>147</td>\n","      <td>169</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars1...</td>\n","      <td>400</td>\n","      <td>268</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>115</td>\n","      <td>277</td>\n","      <td>115</td>\n","      <td>153</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars7...</td>\n","      <td>400</td>\n","      <td>267</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>36</td>\n","      <td>62</td>\n","      <td>175</td>\n","      <td>186</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars1...</td>\n","      <td>400</td>\n","      <td>221</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>71</td>\n","      <td>215</td>\n","      <td>205</td>\n","      <td>246</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars2...</td>\n","      <td>517</td>\n","      <td>303</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            filepath  xmin  xmax  ymin  ymax  \\\n","0  /kaggle/input/car-plate-detection/annotations/...   209   283   135   169   \n","1  /kaggle/input/car-plate-detection/annotations/...   191   242   147   169   \n","2  /kaggle/input/car-plate-detection/annotations/...   115   277   115   153   \n","3  /kaggle/input/car-plate-detection/annotations/...    36    62   175   186   \n","4  /kaggle/input/car-plate-detection/annotations/...    71   215   205   246   \n","\n","                                            filename  width  height  \n","0  /kaggle/input/car-plate-detection/images/Cars3...    500     300  \n","1  /kaggle/input/car-plate-detection/images/Cars1...    400     268  \n","2  /kaggle/input/car-plate-detection/images/Cars7...    400     267  \n","3  /kaggle/input/car-plate-detection/images/Cars1...    400     221  \n","4  /kaggle/input/car-plate-detection/images/Cars2...    517     303  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# parsing\n","def parsing(path):\n","    parser = xet.parse(path).getroot()\n","    name = parser.find('filename').text\n","    filename = f'/kaggle/input/car-plate-detection/images/{name}'\n","\n","    # width and height\n","    parser_size = parser.find('size')\n","    width = int(parser_size.find('width').text)\n","    height = int(parser_size.find('height').text)\n","    \n","    return filename, width, height\n","df[['filename','width','height']] = df['filepath'].apply(parsing).apply(pd.Series)\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Yolo need [class, center_x, center_y, w, h] refers to X and Y center position to the BB and with and height of the BB. "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:12.760734Z","iopub.status.busy":"2023-10-04T10:23:12.760070Z","iopub.status.idle":"2023-10-04T10:23:12.783271Z","shell.execute_reply":"2023-10-04T10:23:12.782194Z","shell.execute_reply.started":"2023-10-04T10:23:12.760697Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepath</th>\n","      <th>xmin</th>\n","      <th>xmax</th>\n","      <th>ymin</th>\n","      <th>ymax</th>\n","      <th>filename</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>center_x</th>\n","      <th>center_y</th>\n","      <th>bb_width</th>\n","      <th>bb_height</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>209</td>\n","      <td>283</td>\n","      <td>135</td>\n","      <td>169</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars3...</td>\n","      <td>500</td>\n","      <td>300</td>\n","      <td>0.492000</td>\n","      <td>0.506667</td>\n","      <td>0.14800</td>\n","      <td>0.113333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>191</td>\n","      <td>242</td>\n","      <td>147</td>\n","      <td>169</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars1...</td>\n","      <td>400</td>\n","      <td>268</td>\n","      <td>0.541250</td>\n","      <td>0.589552</td>\n","      <td>0.12750</td>\n","      <td>0.082090</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>115</td>\n","      <td>277</td>\n","      <td>115</td>\n","      <td>153</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars7...</td>\n","      <td>400</td>\n","      <td>267</td>\n","      <td>0.490000</td>\n","      <td>0.501873</td>\n","      <td>0.40500</td>\n","      <td>0.142322</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>36</td>\n","      <td>62</td>\n","      <td>175</td>\n","      <td>186</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars1...</td>\n","      <td>400</td>\n","      <td>221</td>\n","      <td>0.122500</td>\n","      <td>0.816742</td>\n","      <td>0.06500</td>\n","      <td>0.049774</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/car-plate-detection/annotations/...</td>\n","      <td>71</td>\n","      <td>215</td>\n","      <td>205</td>\n","      <td>246</td>\n","      <td>/kaggle/input/car-plate-detection/images/Cars2...</td>\n","      <td>517</td>\n","      <td>303</td>\n","      <td>0.276596</td>\n","      <td>0.744224</td>\n","      <td>0.27853</td>\n","      <td>0.135314</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            filepath  xmin  xmax  ymin  ymax  \\\n","0  /kaggle/input/car-plate-detection/annotations/...   209   283   135   169   \n","1  /kaggle/input/car-plate-detection/annotations/...   191   242   147   169   \n","2  /kaggle/input/car-plate-detection/annotations/...   115   277   115   153   \n","3  /kaggle/input/car-plate-detection/annotations/...    36    62   175   186   \n","4  /kaggle/input/car-plate-detection/annotations/...    71   215   205   246   \n","\n","                                            filename  width  height  center_x  \\\n","0  /kaggle/input/car-plate-detection/images/Cars3...    500     300  0.492000   \n","1  /kaggle/input/car-plate-detection/images/Cars1...    400     268  0.541250   \n","2  /kaggle/input/car-plate-detection/images/Cars7...    400     267  0.490000   \n","3  /kaggle/input/car-plate-detection/images/Cars1...    400     221  0.122500   \n","4  /kaggle/input/car-plate-detection/images/Cars2...    517     303  0.276596   \n","\n","   center_y  bb_width  bb_height  \n","0  0.506667   0.14800   0.113333  \n","1  0.589552   0.12750   0.082090  \n","2  0.501873   0.40500   0.142322  \n","3  0.816742   0.06500   0.049774  \n","4  0.744224   0.27853   0.135314  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# center_x, center_y, width , height\n","df['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\n","df['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n","\n","df['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\n","df['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preparation"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:16.132787Z","iopub.status.busy":"2023-10-04T10:23:16.131657Z","iopub.status.idle":"2023-10-04T10:23:19.185620Z","shell.execute_reply":"2023-10-04T10:23:19.184298Z","shell.execute_reply.started":"2023-10-04T10:23:16.132726Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16003, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (23/23), done.\u001b[K\n","remote: Total 16003 (delta 21), reused 20 (delta 13), pack-reused 15967\u001b[K\n","Receiving objects: 100% (16003/16003), 14.66 MiB | 25.83 MiB/s, done.\n","Resolving deltas: 100% (10983/10983), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:21.379834Z","iopub.status.busy":"2023-10-04T10:23:21.379279Z","iopub.status.idle":"2023-10-04T10:23:31.590285Z","shell.execute_reply":"2023-10-04T10:23:31.589011Z","shell.execute_reply.started":"2023-10-04T10:23:21.379791Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 5)) (3.1.31)\n","Requirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 6)) (3.7.2)\n","Requirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 7)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 8)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 9)) (9.5.0)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 10)) (5.9.3)\n","Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 13)) (1.11.2)\n","Collecting thop>=0.1.1 (from -r ./yolov5/requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 16)) (0.15.1)\n","Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 17)) (4.66.1)\n","Collecting ultralytics>=8.0.147 (from -r ./yolov5/requirements.txt (line 18))\n","  Downloading ultralytics-8.0.192-py3-none-any.whl (616 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.5/616.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 27)) (2.0.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r ./yolov5/requirements.txt (line 42)) (68.0.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r ./yolov5/requirements.txt (line 5)) (4.0.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (21.3)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r ./yolov5/requirements.txt (line 12)) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r ./yolov5/requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r ./yolov5/requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r ./yolov5/requirements.txt (line 12)) (2023.7.22)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.147->-r ./yolov5/requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r ./yolov5/requirements.txt (line 27)) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r ./yolov5/requirements.txt (line 27)) (2023.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r ./yolov5/requirements.txt (line 5)) (5.0.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r ./yolov5/requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r ./yolov5/requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.192\n"]}],"source":["!pip install -r ./yolov5/requirements.txt"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:31.593598Z","iopub.status.busy":"2023-10-04T10:23:31.592525Z","iopub.status.idle":"2023-10-04T10:23:32.559982Z","shell.execute_reply":"2023-10-04T10:23:32.558533Z","shell.execute_reply.started":"2023-10-04T10:23:31.593549Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:32.562791Z","iopub.status.busy":"2023-10-04T10:23:32.561682Z","iopub.status.idle":"2023-10-04T10:23:33.520261Z","shell.execute_reply":"2023-10-04T10:23:33.518990Z","shell.execute_reply.started":"2023-10-04T10:23:32.562733Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/test/"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:33.523536Z","iopub.status.busy":"2023-10-04T10:23:33.522918Z","iopub.status.idle":"2023-10-04T10:23:34.473508Z","shell.execute_reply":"2023-10-04T10:23:34.472266Z","shell.execute_reply.started":"2023-10-04T10:23:33.523499Z"},"trusted":true},"outputs":[],"source":["mkdir /kaggle/working/yolov5/data_images/train/"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:35.639308Z","iopub.status.busy":"2023-10-04T10:23:35.638126Z","iopub.status.idle":"2023-10-04T10:23:35.645616Z","shell.execute_reply":"2023-10-04T10:23:35.644427Z","shell.execute_reply.started":"2023-10-04T10:23:35.639255Z"},"trusted":true},"outputs":[],"source":["### split the data into train and test\n","df_train = df.iloc[:200]\n","df_test = df.iloc[200:]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:23:36.534903Z","iopub.status.busy":"2023-10-04T10:23:36.533687Z","iopub.status.idle":"2023-10-04T10:23:54.461573Z","shell.execute_reply":"2023-10-04T10:23:54.460607Z","shell.execute_reply.started":"2023-10-04T10:23:36.534858Z"},"trusted":true},"outputs":[],"source":["train_folder = './yolov5/data_images/train'\n","\n","values = df_train[['filename','center_x','center_y','bb_width','bb_height']].values\n","for fname, x,y, w, h in values:\n","    image_name = os.path.split(fname)[-1]\n","    txt_name = os.path.splitext(image_name)[0]\n","    \n","    dst_image_path = os.path.join(train_folder,image_name)\n","    dst_label_file = os.path.join(train_folder,txt_name+'.txt')\n","    \n","    # copy each image into the folder\n","    copy(fname,dst_image_path)\n","\n","    # generate .txt which has label info\n","    label_txt = f'0 {x} {y} {w} {h}'\n","    with open(dst_label_file,mode='w') as f:\n","        f.write(label_txt)\n","        \n","        f.close()\n","\n","test_folder = './yolov5/data_images/test'\n","\n","values = df_test[['filename','center_x','center_y','bb_width','bb_height']].values\n","for fname, x,y, w, h in values:\n","    image_name = os.path.split(fname)[-1]\n","    txt_name = os.path.splitext(image_name)[0]\n","    \n","    dst_image_path = os.path.join(test_folder,image_name)\n","    dst_label_file = os.path.join(test_folder,txt_name+'.txt')\n","    \n","    # copy each image into the folder\n","    copy(fname,dst_image_path)\n","\n","    # generate .txt which has label info\n","    label_txt = f'0 {x} {y} {w} {h}'\n","    with open(dst_label_file,mode='w') as f:\n","        f.write(label_txt)\n","        \n","        f.close()"]},{"cell_type":"markdown","metadata":{},"source":["### training yolo"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:24:05.361404Z","iopub.status.busy":"2023-10-04T10:24:05.360712Z","iopub.status.idle":"2023-10-04T10:24:21.064822Z","shell.execute_reply":"2023-10-04T10:24:21.063863Z","shell.execute_reply.started":"2023-10-04T10:24:05.361374Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting GPUtil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=de1ffa1aab45d9c039eeb12f6e4b19202735682a424af08e2165bb7d613277d2\n","  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n","Initial GPU Usage\n","| ID | GPU | MEM |\n","------------------\n","|  0 |  0% |  0% |\n","|  1 |  0% |  0% |\n","GPU Usage after emptying the cache\n","| ID | GPU | MEM |\n","------------------\n","|  0 |  5% |  1% |\n","|  1 |  0% |  0% |\n"]}],"source":["!pip install GPUtil\n","\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","free_gpu_cache()  "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:24:21.067202Z","iopub.status.busy":"2023-10-04T10:24:21.066624Z","iopub.status.idle":"2023-10-04T10:56:05.779471Z","shell.execute_reply":"2023-10-04T10:56:05.778248Z","shell.execute_reply.started":"2023-10-04T10:24:21.067164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=./yolov5/models/yolov5s.yaml, data=/kaggle/input/data-yaml-enr/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 26.1MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5/yolov5s.pt...\n","100%|██████████████████████████████████████| 14.1M/14.1M [00:00<00:00, 74.6MB/s]\n","\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n","\n","Transferred 342/349 items from yolov5/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n","See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/data_images/train... 200 images, 0 backgr\u001b[0m\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/data_images/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/data_images/test... 233 images, 0 backgroun\u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5/data_images/test.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.99 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to yolov5/runs/train/Model/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 1 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/Model\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/99      1.11G     0.1135    0.02858          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233     0.0011       0.33    0.00132   0.000297\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/99       1.4G     0.0949    0.02418          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233    0.00192      0.571    0.00462    0.00111\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/99       1.4G    0.08225     0.0211          0         21        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.039      0.395     0.0506    0.00985\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/99       1.4G    0.08266    0.01818          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.197     0.0601     0.0649     0.0124\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/99       1.4G    0.07833    0.01673          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233    0.00318      0.953      0.101     0.0251\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/99       1.4G     0.0702    0.01868          0          9        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.271     0.0901      0.142     0.0353\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/99       1.4G     0.0626    0.01725          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.472      0.348      0.345      0.125\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/99       1.4G    0.06127    0.01653          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.576      0.403      0.449      0.167\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/99       1.4G    0.05584    0.01581          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.586      0.443      0.521      0.201\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/99       1.4G    0.05473     0.0162          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.53      0.538      0.547      0.215\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/99       1.4G     0.0534     0.0159          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.61      0.531      0.625      0.251\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/99       1.4G    0.04939    0.01454          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.648      0.541      0.627      0.227\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/99       1.4G    0.04988    0.01456          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.618      0.609       0.65      0.251\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/99       1.4G    0.04893    0.01372          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.701      0.618      0.664      0.256\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/99       1.4G     0.0458    0.01345          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.78      0.545      0.705       0.27\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/99       1.4G     0.0446    0.01224          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.748      0.752      0.811      0.393\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/99       1.4G     0.0424     0.0124          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.739      0.605      0.737      0.327\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/99       1.4G    0.04391    0.01173          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.746       0.73      0.811      0.407\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/99       1.4G    0.04147    0.01193          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.847        0.5      0.712      0.329\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/99       1.4G    0.04287    0.01075          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.813      0.794      0.828      0.386\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/99       1.4G    0.04311    0.01112          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.814       0.79      0.844      0.372\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/99       1.4G     0.0419    0.01027          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.765      0.823      0.823      0.369\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/99       1.4G    0.04102   0.009804          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.883      0.773      0.878      0.443\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/99       1.4G    0.03645    0.01031          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.62      0.734      0.755      0.371\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/99       1.4G    0.03874   0.009747          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.815      0.833      0.869      0.459\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/99       1.4G    0.03818    0.01072          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.797       0.82      0.867      0.477\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/99       1.4G    0.03758   0.009272          0         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.804       0.88      0.871      0.431\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/99       1.4G    0.03859   0.009895          0         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.824      0.833       0.86        0.4\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/99       1.4G    0.03701   0.009584          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.829      0.789      0.862      0.424\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/99       1.4G    0.03528    0.00849          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.861      0.822      0.886      0.463\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/99       1.4G    0.03537   0.009037          0         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.83      0.845      0.872      0.381\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/99       1.4G     0.0367   0.008309          0          9        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.895      0.802       0.87      0.425\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/99       1.4G    0.03361   0.008608          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.892      0.833      0.884      0.433\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/99       1.4G    0.03621   0.008301          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.852      0.865      0.877      0.434\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/99       1.4G    0.03414   0.008389          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.824      0.886      0.886      0.442\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/99       1.4G     0.0335   0.008373          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.845      0.865      0.888      0.423\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/99       1.4G    0.03322   0.008454          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.848      0.876      0.901      0.494\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/99       1.4G    0.03303   0.008356          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.841      0.876      0.885      0.471\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/99       1.4G     0.0329    0.00777          0         20        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.864      0.903      0.889      0.485\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/99       1.4G    0.03081   0.008391          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.879      0.863      0.892      0.458\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/99       1.4G    0.03006   0.007776          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.836      0.897      0.895      0.432\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/99       1.4G    0.03208    0.00822          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.872      0.903      0.926      0.506\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/99       1.4G    0.03121   0.008084          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233        0.9      0.849      0.906      0.484\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/99       1.4G    0.03261   0.007931          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.859      0.845      0.884      0.479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/99       1.4G    0.03102   0.008085          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.892      0.876      0.902      0.458\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/99       1.4G    0.03182   0.007864          0         20        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.86      0.896      0.913      0.485\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/99       1.4G    0.02856   0.007631          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.843      0.829      0.897        0.5\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/99       1.4G    0.02973   0.007405          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.861      0.852      0.894      0.503\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/99       1.4G    0.02861   0.007494          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.851      0.857      0.898      0.484\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/99       1.4G    0.02821   0.007784          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.831      0.889        0.9      0.463\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      50/99       1.4G    0.03041   0.007796          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.816      0.877      0.868      0.446\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      51/99       1.4G    0.02967    0.00686          0          9        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.87      0.858       0.89      0.448\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      52/99       1.4G    0.02848   0.008153          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.834      0.863      0.858      0.446\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      53/99       1.4G    0.02836   0.007183          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.863       0.88      0.892      0.467\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      54/99       1.4G    0.02654   0.007871          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.899      0.843       0.89      0.424\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      55/99       1.4G    0.02868   0.006632          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.883      0.844      0.867      0.456\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      56/99       1.4G    0.02686   0.007233          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233        0.9       0.82      0.867       0.48\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      57/99       1.4G    0.02729   0.006944          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.869      0.857      0.859      0.483\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      58/99       1.4G      0.027   0.006877          0         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.86      0.858      0.864      0.478\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      59/99       1.4G    0.02756   0.006908          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.853      0.854      0.866      0.477\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      60/99       1.4G    0.02679   0.006956          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.882      0.837      0.881      0.485\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      61/99       1.4G    0.02625   0.006838          0         23        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.851      0.876      0.881      0.479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      62/99       1.4G    0.02605   0.007606          0         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.866      0.862      0.881      0.476\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      63/99       1.4G    0.02583    0.00689          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.865       0.85      0.874      0.456\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      64/99       1.4G     0.0249   0.006985          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.858      0.833      0.853      0.463\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      65/99       1.4G    0.02397   0.006875          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.889      0.841      0.881      0.475\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      66/99       1.4G    0.02523   0.006841          0         21        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.853      0.821      0.867      0.477\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      67/99       1.4G    0.02481   0.006455          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.87      0.858      0.902      0.479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      68/99       1.4G    0.02418   0.006524          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.864      0.875       0.88      0.484\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      69/99       1.4G    0.02309   0.006691          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.835      0.869      0.854      0.469\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      70/99       1.4G    0.02355   0.006934          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.833      0.898      0.877      0.496\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      71/99       1.4G    0.02336   0.006896          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.846      0.893      0.874      0.483\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      72/99       1.4G    0.02283   0.006344          0         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.846      0.906      0.878      0.484\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      73/99       1.4G    0.02336   0.006506          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.825      0.911       0.89      0.499\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      74/99       1.4G    0.02279   0.007239          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.861      0.879       0.88      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      75/99       1.4G    0.02183   0.006197          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.848      0.897      0.874      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      76/99       1.4G    0.02269   0.006154          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.852      0.884      0.863      0.476\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      77/99       1.4G    0.02297   0.006817          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.846      0.893      0.868       0.47\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      78/99       1.4G    0.02349   0.006505          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.83      0.898       0.86      0.466\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      79/99       1.4G    0.02159   0.006985          0         21        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.827       0.91      0.853      0.454\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      80/99       1.4G    0.02163   0.006579          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.828      0.909      0.866      0.467\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      81/99       1.4G     0.0225   0.006462          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.843      0.875      0.878      0.468\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      82/99       1.4G    0.02161   0.006086          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.848      0.864      0.873      0.471\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      83/99       1.4G    0.02144    0.00599          0         23        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.863       0.85      0.874      0.481\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      84/99       1.4G    0.02063   0.006006          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.853      0.876      0.877      0.479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      85/99       1.4G    0.02014   0.006064          0         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.864      0.871      0.881      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      86/99       1.4G    0.02005   0.005848          0         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.85      0.893      0.886      0.489\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      87/99       1.4G     0.0197   0.006295          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.829      0.906      0.877      0.491\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      88/99       1.4G     0.0198   0.005848          0         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.829      0.893      0.873      0.493\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      89/99       1.4G    0.01999   0.005657          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.83      0.902      0.871      0.483\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      90/99       1.4G    0.01955   0.005653          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.829      0.893       0.87       0.48\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      91/99       1.4G    0.02112   0.006041          0         21        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.829      0.901       0.86      0.477\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      92/99       1.4G    0.01983   0.005958          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.856      0.866      0.865      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      93/99       1.4G    0.01989   0.005788          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.831      0.886      0.861      0.488\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      94/99       1.4G    0.02052   0.006021          0         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.835      0.884      0.868      0.488\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      95/99       1.4G    0.01874   0.005779          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.851      0.879      0.874      0.491\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      96/99       1.4G     0.0201   0.005925          0         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.85      0.878      0.871      0.489\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      97/99       1.4G      0.019   0.005895          0         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.862      0.884      0.886      0.491\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      98/99       1.4G    0.01982    0.00626          0         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.844      0.881      0.874      0.486\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      99/99       1.4G    0.01884   0.006164          0         20        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233       0.84      0.877      0.864      0.482\n","\n","100 epochs completed in 0.505 hours.\n","Optimizer stripped from yolov5/runs/train/Model/weights/last.pt, 14.4MB\n","Optimizer stripped from yolov5/runs/train/Model/weights/best.pt, 14.4MB\n","\n","Validating yolov5/runs/train/Model/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        233        233      0.872      0.902      0.926      0.506\n","Results saved to \u001b[1myolov5/runs/train/Model\u001b[0m\n"]}],"source":["!python ./yolov5/train.py --data /kaggle/input/data-yaml-enr/data.yaml --cfg ./yolov5/models/yolov5s.yaml --batch-size 8 --name Model --epochs 100"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T10:57:20.565855Z","iopub.status.busy":"2023-10-04T10:57:20.565456Z","iopub.status.idle":"2023-10-04T10:57:30.933954Z","shell.execute_reply":"2023-10-04T10:57:30.932838Z","shell.execute_reply.started":"2023-10-04T10:57:20.565822Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mexport: \u001b[0mdata=yolov5/data/coco128.yaml, weights=['./yolov5/runs/train/Model/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\n","YOLOv5 🚀 v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.0 CPU\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5/runs/train/Model/weights/best.pt with output shape (1, 25200, 6) (13.8 MB)\n","\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.0...\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 2.3s, saved as yolov5/runs/train/Model/weights/best.torchscript (27.2 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n","================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.1s, saved as yolov5/runs/train/Model/weights/best.onnx (27.2 MB)\n","\n","Export complete (4.3s)\n","Results saved to \u001b[1m/kaggle/working/yolov5/runs/train/Model/weights\u001b[0m\n","Detect:          python detect.py --weights yolov5/runs/train/Model/weights/best.onnx \n","Validate:        python val.py --weights yolov5/runs/train/Model/weights/best.onnx \n","PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5/runs/train/Model/weights/best.onnx')  \n","Visualize:       https://netron.app\n"]}],"source":["!python ./yolov5/export.py --weight ./yolov5/runs/train/Model/weights/best.pt --include torchscript onnx"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
